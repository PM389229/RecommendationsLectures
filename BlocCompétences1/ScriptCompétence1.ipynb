{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloc de compétences 1 : Réaliser la collecte, le stockage et la mise à disposition des données d’un projet en intelligence artificielle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1. Automatiser l’extraction de données depuis un service web, une page web (scraping*), un fichier de données, une base de données et un système big data* en, programmant le script* adapté afin de\n",
    "# pérenniser la collecte des données nécessaires au projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On a donc commencé par récupérer un dataset de 7000 livres avec toutes les infos nécessaires provenant \n",
    "# de Goodreads books avant qu'il soit difficile d'obtenir une clef API (7K Books sur kaggle ) afin d'avoir une 'Base' solide de livres \n",
    "# (GoodReads Books a été racheté pr Amazon en  2013 et depuis l'utilisation de son API est limité et il est difficile d'obtenir une clef aujourd'hui)\n",
    "# Ce dataset est bien car il a les couvertures rattachés aux informations des livres ce qui peut etre une bonne chose pour l'affichage sur la future plateforme\n",
    "# Petit soucis le dataset date d'il y a deja un moment ce qui peut etre un defaut donc il faut recuperer des livres sortis après sa création \n",
    "# (post septembre 2019 donc a minima) ? J'ai donc pensé à recuperer les best-sellers pour une periode donnée (Script -1-)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn13</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>description</th>\n",
       "      <th>published_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9780002005883</td>\n",
       "      <td>0002005883</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marilynne Robinson</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=KQZCP...</td>\n",
       "      <td>A NOVEL THAT READERS and critics have been eag...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>247.0</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9780002261982</td>\n",
       "      <td>0002261987</td>\n",
       "      <td>Spider's Web</td>\n",
       "      <td>A Novel</td>\n",
       "      <td>Charles Osborne;Agatha Christie</td>\n",
       "      <td>Detective and mystery stories</td>\n",
       "      <td>http://books.google.com/books/content?id=gA5GP...</td>\n",
       "      <td>A new 'Christie for Christmas' -- a full-lengt...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>241.0</td>\n",
       "      <td>5164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780006163831</td>\n",
       "      <td>0006163831</td>\n",
       "      <td>The One Tree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stephen R. Donaldson</td>\n",
       "      <td>American fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=OmQaw...</td>\n",
       "      <td>Volume Two of Stephen Donaldson's acclaimed se...</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>479.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9780006178736</td>\n",
       "      <td>0006178731</td>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sidney Sheldon</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=FKo2T...</td>\n",
       "      <td>A memorable, mesmerizing heroine Jennifer -- b...</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>512.0</td>\n",
       "      <td>29532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9780006280897</td>\n",
       "      <td>0006280897</td>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clive Staples Lewis</td>\n",
       "      <td>Christian life</td>\n",
       "      <td>http://books.google.com/books/content?id=XhQ5X...</td>\n",
       "      <td>Lewis' work on the nature of love divides love...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>170.0</td>\n",
       "      <td>33684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>9788185300535</td>\n",
       "      <td>8185300534</td>\n",
       "      <td>I Am that</td>\n",
       "      <td>Talks with Sri Nisargadatta Maharaj</td>\n",
       "      <td>Sri Nisargadatta Maharaj;Sudhakar S. Dikshit</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>http://books.google.com/books/content?id=Fv_JP...</td>\n",
       "      <td>This collection of the timeless teachings of o...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>531.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>9788185944609</td>\n",
       "      <td>8185944601</td>\n",
       "      <td>Secrets Of The Heart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Khalil Gibran</td>\n",
       "      <td>Mysticism</td>\n",
       "      <td>http://books.google.com/books/content?id=XcrVp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>74.0</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>9788445074879</td>\n",
       "      <td>8445074873</td>\n",
       "      <td>Fahrenheit 451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ray Bradbury</td>\n",
       "      <td>Book burning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>3.98</td>\n",
       "      <td>186.0</td>\n",
       "      <td>5733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6808</th>\n",
       "      <td>9789027712059</td>\n",
       "      <td>9027712050</td>\n",
       "      <td>The Berlin Phenomenology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Georg Wilhelm Friedrich Hegel</td>\n",
       "      <td>History</td>\n",
       "      <td>http://books.google.com/books/content?id=Vy7Sk...</td>\n",
       "      <td>Since the three volume edition ofHegel's Philo...</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6809</th>\n",
       "      <td>9789042003408</td>\n",
       "      <td>9042003405</td>\n",
       "      <td>'I'm Telling You Stories'</td>\n",
       "      <td>Jeanette Winterson and the Politics of Reading</td>\n",
       "      <td>Helena Grice;Tim Woods</td>\n",
       "      <td>Literary Criticism</td>\n",
       "      <td>http://books.google.com/books/content?id=2lVyR...</td>\n",
       "      <td>This is a jubilant and rewarding collection of...</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>136.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6810 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn13      isbn10                      title  \\\n",
       "0     9780002005883  0002005883                     Gilead   \n",
       "1     9780002261982  0002261987               Spider's Web   \n",
       "2     9780006163831  0006163831               The One Tree   \n",
       "3     9780006178736  0006178731             Rage of angels   \n",
       "4     9780006280897  0006280897             The Four Loves   \n",
       "...             ...         ...                        ...   \n",
       "6805  9788185300535  8185300534                  I Am that   \n",
       "6806  9788185944609  8185944601       Secrets Of The Heart   \n",
       "6807  9788445074879  8445074873             Fahrenheit 451   \n",
       "6808  9789027712059  9027712050   The Berlin Phenomenology   \n",
       "6809  9789042003408  9042003405  'I'm Telling You Stories'   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0                                                NaN   \n",
       "1                                            A Novel   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "...                                              ...   \n",
       "6805             Talks with Sri Nisargadatta Maharaj   \n",
       "6806                                             NaN   \n",
       "6807                                             NaN   \n",
       "6808                                             NaN   \n",
       "6809  Jeanette Winterson and the Politics of Reading   \n",
       "\n",
       "                                           authors  \\\n",
       "0                               Marilynne Robinson   \n",
       "1                  Charles Osborne;Agatha Christie   \n",
       "2                             Stephen R. Donaldson   \n",
       "3                                   Sidney Sheldon   \n",
       "4                              Clive Staples Lewis   \n",
       "...                                            ...   \n",
       "6805  Sri Nisargadatta Maharaj;Sudhakar S. Dikshit   \n",
       "6806                                 Khalil Gibran   \n",
       "6807                                  Ray Bradbury   \n",
       "6808                 Georg Wilhelm Friedrich Hegel   \n",
       "6809                        Helena Grice;Tim Woods   \n",
       "\n",
       "                         categories  \\\n",
       "0                           Fiction   \n",
       "1     Detective and mystery stories   \n",
       "2                  American fiction   \n",
       "3                           Fiction   \n",
       "4                    Christian life   \n",
       "...                             ...   \n",
       "6805                     Philosophy   \n",
       "6806                      Mysticism   \n",
       "6807                   Book burning   \n",
       "6808                        History   \n",
       "6809             Literary Criticism   \n",
       "\n",
       "                                              thumbnail  \\\n",
       "0     http://books.google.com/books/content?id=KQZCP...   \n",
       "1     http://books.google.com/books/content?id=gA5GP...   \n",
       "2     http://books.google.com/books/content?id=OmQaw...   \n",
       "3     http://books.google.com/books/content?id=FKo2T...   \n",
       "4     http://books.google.com/books/content?id=XhQ5X...   \n",
       "...                                                 ...   \n",
       "6805  http://books.google.com/books/content?id=Fv_JP...   \n",
       "6806  http://books.google.com/books/content?id=XcrVp...   \n",
       "6807                                                NaN   \n",
       "6808  http://books.google.com/books/content?id=Vy7Sk...   \n",
       "6809  http://books.google.com/books/content?id=2lVyR...   \n",
       "\n",
       "                                            description  published_year  \\\n",
       "0     A NOVEL THAT READERS and critics have been eag...          2004.0   \n",
       "1     A new 'Christie for Christmas' -- a full-lengt...          2000.0   \n",
       "2     Volume Two of Stephen Donaldson's acclaimed se...          1982.0   \n",
       "3     A memorable, mesmerizing heroine Jennifer -- b...          1993.0   \n",
       "4     Lewis' work on the nature of love divides love...          2002.0   \n",
       "...                                                 ...             ...   \n",
       "6805  This collection of the timeless teachings of o...          1999.0   \n",
       "6806                                                NaN          1993.0   \n",
       "6807                                                NaN          2004.0   \n",
       "6808  Since the three volume edition ofHegel's Philo...          1981.0   \n",
       "6809  This is a jubilant and rewarding collection of...          1998.0   \n",
       "\n",
       "      average_rating  num_pages  ratings_count  \n",
       "0               3.85      247.0          361.0  \n",
       "1               3.83      241.0         5164.0  \n",
       "2               3.97      479.0          172.0  \n",
       "3               3.93      512.0        29532.0  \n",
       "4               4.15      170.0        33684.0  \n",
       "...              ...        ...            ...  \n",
       "6805            4.51      531.0          104.0  \n",
       "6806            4.08       74.0          324.0  \n",
       "6807            3.98      186.0         5733.0  \n",
       "6808            0.00      210.0            0.0  \n",
       "6809            3.70      136.0           10.0  \n",
       "\n",
       "[6810 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title               Author  \\\n",
      "0                        THE EVENING AND THE MORNING          Ken Follett   \n",
      "1                           VINCE FLYNN: TOTAL POWER           Kyle Mills   \n",
      "2                                     TROUBLED BLOOD     Robert Galbraith   \n",
      "3                         TO SLEEP IN A SEA OF STARS  Christopher Paolini   \n",
      "4                                   SHADOWS IN DEATH            J.D. Robb   \n",
      "..                                               ...                  ...   \n",
      "225                         THIS BOOK IS ANTI-RACIST      Tiffany Jewell.   \n",
      "226  THE ABSOLUTELY TRUE DIARY OF A PART-TIME INDIAN      Sherman Alexie.   \n",
      "227                         THEY BOTH DIE AT THE END         Adam Silvera   \n",
      "228                   THE BOY IN THE STRIPED PAJAMAS           John Boyne   \n",
      "229           I AM NOT YOUR PERFECT MEXICAN DAUGHTER     Erika L. Sánchez   \n",
      "\n",
      "          Published_Date                                        Description  \n",
      "0    Date non disponible  In a prequel to “The Pillars of the Earth,” a ...  \n",
      "1    Date non disponible  When America’s power grid is shut down, Mitch ...  \n",
      "2    Date non disponible  The fifth book in the Cormoran Strike series. ...  \n",
      "3    Date non disponible  Kira Navárez might be the only one who can sav...  \n",
      "4    Date non disponible  The 51st book of the In Death series. A hitman...  \n",
      "..                   ...                                                ...  \n",
      "225  Date non disponible                                                     \n",
      "226  Date non disponible                                                     \n",
      "227  Date non disponible                                                     \n",
      "228  Date non disponible                                                     \n",
      "229  Date non disponible                                                     \n",
      "\n",
      "[230 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 1 - Ce script permet d'obtenir tous les best sellers à une date donnée avec cet endpoint , get\t/lists/full-overview.json\t\n",
    "\n",
    "# \"Get all books for all the Best Sellers lists for specified date.\" , on ne peut pas avoir les best sellers sur une année mais à une date donnée oui\n",
    "\n",
    "# Votre clé API NYT\n",
    "API_KEY = \"lC2n3VNjSgTbTRPngMEXXwi3DgFsZiiM\"\n",
    "\n",
    "# Fonction pour obtenir les best-sellers pour une date spécifique\n",
    "def get_best_sellers_by_date(date):\n",
    "    url = f\"https://api.nytimes.com/svc/books/v3/lists/full-overview.json?published_date={date}&api-key={API_KEY}\"\n",
    "    \n",
    "    # Faire la requête API\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        books = []\n",
    "        count = 0  # Limite de livres\n",
    "\n",
    "        # Parcourir les listes de best-sellers\n",
    "        for list_data in data[\"results\"][\"lists\"]:\n",
    "            for book in list_data[\"books\"]:\n",
    "                books.append({\n",
    "                    \"Title\": book[\"title\"],\n",
    "                    \"Author\": book[\"author\"],\n",
    "                    \"Published_Date\": book.get(\"published_date\", \"Date non disponible\"),\n",
    "                    \"Description\": book.get(\"description\", \"Description non disponible\")\n",
    "                })\n",
    "                count += 1\n",
    "\n",
    "        # Créer un DataFrame et afficher les résultats\n",
    "        df_books = pd.DataFrame(books)\n",
    "        print(df_books)\n",
    "\n",
    "        # Sauvegarder en CSV\n",
    "        df_books.to_csv(f\"nyt_best_sellers_{date}.csv\", index=False)\n",
    "    else:\n",
    "        print(f\"Erreur {response.status_code} lors de la récupération des données.\")\n",
    "\n",
    "# Exemple d'appel pour une date donnée (1er janvier 2023)\n",
    "get_best_sellers_by_date(\"2020-09-30\")\n",
    "\n",
    "#On prend la date la plus reculée dans l'année choisie pour qu'un maximum de livres soient sortis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problème l'API de New York Times ne fournit pas la date de publication dans son API , essayons de les recuperer avec open library ou google books ?\n",
    "# On va donc continuer par montrer comment récupérer des informations sur l'API de Google Books avec une clef API \n",
    "#L'idée est de compléter le dataset avec les données récupérées ici pour une année donnée (pour l'instant)\n",
    "# Recuperation par API de Google Books des dates de sorties des livres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur 429: Trop de requêtes. Attente avant de réessayer...\n",
      "Aucun livre trouvé pour : DIARY OF A WIMPY KID de and   Jeff Kinney\n",
      "Résultats sauvegardés dans books_2020.csv.\n"
     ]
    }
   ],
   "source": [
    "# 2 On va ici recuperer le dataset csv fait avec l'API du NYTIME pour avoir une liste au format 'nyt_best_sellers_2024-09-30.csv ', la completer avec l'API de Google Books (avoir la date de sortie pour chaque livre) \n",
    "# et ne conserver que sortis en 2023 dans books_2023 car il peut y avoir des erreurs (des best-sellers de 2023 ne sont pas forcement sortis cette année) , un nouveau csv en sortie est créé\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Votre clé API Google Cloud\n",
    "API_KEY = \"AIzaSyB58AGjlxZuHqtNTOrceKqzgE8eNZNxebk\"\n",
    "\n",
    "# Fonction pour récupérer les détails d'un livre via l'API Google Books\n",
    "def rechercher_livres_par_titre_auteur(titre, auteur):\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes?q=intitle:{titre}+inauthor:{auteur}&key={API_KEY}\"\n",
    "    retry_count = 0\n",
    "    max_retries = 5  # Nombre maximum de réessais\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"items\" in data:\n",
    "                livre = data[\"items\"][0][\"volumeInfo\"]\n",
    "                return {\n",
    "                    \"title\": livre.get(\"title\", \"Titre non disponible\"),\n",
    "                    \"authors\": \", \".join(livre.get(\"authors\", [\"Auteur non disponible\"])),\n",
    "                    \"description\": livre.get(\"description\", \"Description non disponible\"),\n",
    "                    \"average_rating\": livre.get(\"averageRating\", \"Note non disponible\"),\n",
    "                    \"published_date\": livre.get(\"publishedDate\", \"Date de publication non disponible\"),\n",
    "                    \"categories\": \", \".join(livre.get(\"categories\", [\"Catégorie non disponible\"]))\n",
    "                }\n",
    "            else:\n",
    "                print(f\"Aucun livre trouvé pour : {titre} de {auteur}\")\n",
    "                return None\n",
    "        elif response.status_code == 429:\n",
    "            print(f\"Erreur 429: Trop de requêtes. Attente avant de réessayer...\")\n",
    "            retry_count += 1\n",
    "            time.sleep(30 * retry_count)  # Attendre de plus en plus longtemps après chaque échec\n",
    "        else:\n",
    "            print(f\"Erreur {response.status_code}: Impossible de récupérer les données pour {titre} de {auteur}.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "# Fonction pour lire les livres à partir du fichier CSV\n",
    "def charger_livres_du_csv(chemin_csv):\n",
    "    try:\n",
    "        # Charger le fichier CSV avec les colonnes 'Title' et 'Author'\n",
    "        df = pd.read_csv(chemin_csv)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fichier {chemin_csv} non trouvé.\")\n",
    "        return pd.DataFrame()  # Retourner un DataFrame vide en cas d'erreur\n",
    "\n",
    "# Fonction pour sauvegarder les résultats dans un CSV\n",
    "def sauvegarder_resultats(annee, resultats):\n",
    "    # Nommer le fichier CSV en fonction de l'année\n",
    "    chemin_csv = f\"books_{annee}.csv\"\n",
    "    \n",
    "    # Créer un DataFrame à partir des résultats et sauvegarder dans un fichier CSV\n",
    "    df = pd.DataFrame(resultats)\n",
    "    df.to_csv(chemin_csv, index=False)\n",
    "    print(f\"Résultats sauvegardés dans {chemin_csv}.\")\n",
    "\n",
    "# Fonction principale\n",
    "def main(annee, date):\n",
    "    # Utiliser la date spécifiée pour nommer le fichier CSV correctement\n",
    "    chemin_csv = f\"nyt_best_sellers_{date}.csv\"\n",
    "    \n",
    "    # Charger les livres depuis le fichier CSV correspondant\n",
    "    df_livres = charger_livres_du_csv(chemin_csv)\n",
    "\n",
    "    # Liste pour stocker les résultats\n",
    "    resultats = []\n",
    "\n",
    "    # Si le DataFrame est non vide, rechercher les informations via Google Books API\n",
    "    if not df_livres.empty:\n",
    "        for index, row in df_livres.iterrows():\n",
    "            livre_info = rechercher_livres_par_titre_auteur(row[\"Title\"], row[\"Author\"])\n",
    "            if livre_info:\n",
    "                # Filtrer les livres publiés dans l'année donnée\n",
    "                published_date = livre_info.get(\"published_date\")\n",
    "                if published_date and str(annee) in published_date:\n",
    "                    resultats.append(livre_info)\n",
    "        \n",
    "        # Sauvegarder les résultats dans un CSV\n",
    "        sauvegarder_resultats(annee, resultats)\n",
    "    else:\n",
    "        print(f\"Aucun livre trouvé dans le fichier {chemin_csv}.\")\n",
    "\n",
    "# Exemple d'appel pour l'année 2019 avec une date précise (format YYYY-MM-DD)\n",
    "main(2020, \"2020-09-30\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre : Iron Flame\n",
      "Auteur : Rebecca Yarros\n",
      "Note moyenne : Note non disponible\n",
      "Nombre de critiques : Nombre de critiques non disponible\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ce script utilise l'API Google Books comme prévu pour rechercher des informations sur un livre à partir de son titre et de son auteur ,\n",
    "#  c'est un test avant de l'étendre à une liste de livre\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "# Votre clé API Google Books\n",
    "API_KEY = \"AIzaSyB58AGjlxZuHqtNTOrceKqzgE8eNZNxebk\"\n",
    "\n",
    "# Fonction pour rechercher un livre par titre et auteur\n",
    "def rechercher_livres_googlebooks(titre, auteur):\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes?q=intitle:{titre}+inauthor:{auteur}&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if \"items\" in data:\n",
    "            livre = data[\"items\"][0][\"volumeInfo\"]\n",
    "            # Extraire les informations principales\n",
    "            return {\n",
    "                \"titre\": livre.get(\"title\", \"Titre non disponible\"),\n",
    "                \"auteur\": \", \".join(livre.get(\"authors\", [\"Auteur non disponible\"])),\n",
    "                \"note_moyenne\": livre.get(\"averageRating\", \"Note non disponible\"),\n",
    "                \"nombre_de_pages\": livre.get(\"pageCount\", \"Nombre de pages non disponible\"),\n",
    "                \"nombre_de_critiques\": livre.get(\"ratingsCount\", \"Nombre de critiques non disponible\")\n",
    "            }\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Erreur lors de la requête API : {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Exemple d'utilisation\n",
    "titre = \"Iron Flame\"\n",
    "auteur = \"Rebecca Yarros\"\n",
    "livre_info = rechercher_livres_googlebooks(titre, auteur)\n",
    "\n",
    "if livre_info:\n",
    "    print(f\"Titre : {livre_info['titre']}\")\n",
    "    print(f\"Auteur : {livre_info['auteur']}\")\n",
    "    print(f\"Note moyenne : {livre_info['note_moyenne']}\")\n",
    "    print(f\"Nombre de critiques : {livre_info['nombre_de_critiques']}\")\n",
    "else:\n",
    "    print(\"Aucun livre trouvé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Il faut maintenant essayer de l'appliquer a d'autres années , faire les autres methodes pour ces autres années et concatener en un seul dataset\n",
    "#Un probleme rencontré est le manque de notes à la création des datasets complémentaires , on va donc scraper goodreads ce qui ajoute une methode et permet de recuperer ces informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certains sites (comme Goodreads) utilisent JavaScript pour charger dynamiquement les éléments de la page après que la page a été initialement rendue. \n",
    "# BeautifulSoup ne traite pas le JavaScript, donc si les notes sont chargées dynamiquement, elles ne seront pas disponibles au moment où BeautifulSoup récupère la page.\n",
    "\n",
    "# Solution : Utiliser Selenium pour gérer le JavaScript\n",
    "# Selenium est une bibliothèque qui permet d'automatiser un navigateur réel, ce qui signifie qu'il peut traiter les pages qui utilisent du JavaScript pour charger des éléments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\user\\downloads\\coursalternance\\chefoeuvre\\recommendationslectures\\env\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Using cached trio-0.26.2-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user\\downloads\\coursalternance\\chefoeuvre\\recommendationslectures\\env\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Collecting typing_extensions~=4.9 (from selenium)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting websocket-client~=1.8 (from selenium)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\downloads\\coursalternance\\chefoeuvre\\recommendationslectures\\env\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\user\\downloads\\coursalternance\\chefoeuvre\\recommendationslectures\\env\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Collecting cffi>=1.14 (from trio~=0.17->selenium)\n",
      "  Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->trio~=0.17->selenium)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user\\downloads\\coursalternance\\chefoeuvre\\recommendationslectures\\env\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.9.0)\n",
      "Downloading selenium-4.25.0-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.7 MB 670.4 kB/s eta 0:00:14\n",
      "   --- ------------------------------------ 0.8/9.7 MB 699.0 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 0.8/9.7 MB 699.0 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.3/9.7 MB 932.1 kB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.6/9.7 MB 1.0 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.6/9.7 MB 1.0 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.8/9.7 MB 923.6 kB/s eta 0:00:09\n",
      "   ------- -------------------------------- 1.8/9.7 MB 923.6 kB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.1/9.7 MB 851.1 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.4/9.7 MB 913.0 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.4/9.7 MB 913.0 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 2.6/9.7 MB 853.0 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 2.9/9.7 MB 860.3 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.1/9.7 MB 882.9 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.1/9.7 MB 882.9 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.1/9.7 MB 882.9 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.1/9.7 MB 882.9 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 3.4/9.7 MB 737.4 kB/s eta 0:00:09\n",
      "   -------------- ------------------------- 3.4/9.7 MB 737.4 kB/s eta 0:00:09\n",
      "   --------------- ------------------------ 3.7/9.7 MB 752.1 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 3.9/9.7 MB 777.7 kB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 4.2/9.7 MB 783.9 kB/s eta 0:00:08\n",
      "   ------------------ --------------------- 4.5/9.7 MB 803.7 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 4.5/9.7 MB 803.7 kB/s eta 0:00:07\n",
      "   ------------------- -------------------- 4.7/9.7 MB 775.0 kB/s eta 0:00:07\n",
      "   -------------------- ------------------- 5.0/9.7 MB 792.6 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.0/9.7 MB 792.6 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.2/9.7 MB 800.9 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 5.5/9.7 MB 816.4 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 5.8/9.7 MB 825.1 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.0/9.7 MB 835.1 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.0/9.7 MB 835.1 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.3/9.7 MB 817.5 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 6.6/9.7 MB 830.2 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 6.8/9.7 MB 828.9 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.1/9.7 MB 842.1 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.1/9.7 MB 842.1 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 7.3/9.7 MB 845.1 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.6/9.7 MB 855.7 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 7.9/9.7 MB 858.1 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 8.1/9.7 MB 867.8 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.4/9.7 MB 869.7 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.7/9.7 MB 880.1 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 8.9/9.7 MB 884.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.2/9.7 MB 892.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.7 MB 903.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.7 MB 903.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 892.9 kB/s eta 0:00:00\n",
      "Using cached trio-0.26.2-py3-none-any.whl (475 kB)\n",
      "Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, websocket-client, typing_extensions, pysocks, pycparser, attrs, outcome, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-24.2.0 cffi-1.17.1 outcome-1.3.0.post0 pycparser-2.22 pysocks-1.7.1 selenium-4.25.0 sortedcontainers-2.4.0 trio-0.26.2 trio-websocket-0.11.1 typing_extensions-4.12.2 websocket-client-1.8.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il faut ensite Téléchargez le WebDriver correspondant à notre navigateur (comme GeckoDriver pour Mozilla) et placez-le dans votre chemin d'accès.\n",
    "# passé bcp de temps a essayer de faire marcher geckodriver pour firefox mais ca n'a  pas fonctionné on teste avec chromedriver\n",
    "\n",
    "# Infos pour futur MAJ , systeme 64 bits\n",
    "# Lien pour les dernieres versions https://googlechromelabs.github.io/chrome-for-testing/#stable\n",
    "\n",
    "# IL FAUT BLOQUER LES MAJ futures de CHROME : Fait avec l'éditeur de registre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Spécifie le chemin complet vers ChromeDriver\n",
    "service = Service(executable_path=r'C:\\Users\\User\\Downloads\\CoursAlternance\\Chefoeuvre\\RecommendationsLectures\\chromedriver-win64\\chromedriver.exe')\n",
    "\n",
    "# Créer une instance du navigateur Chrome avec le chemin du ChromeDriver\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Ouvrir une page web (ex: Google)\n",
    "driver.get(\"https://www.google.com\")\n",
    "\n",
    "# Afficher le titre de la page\n",
    "print(driver.title)\n",
    "\n",
    "# Fermer le navigateur après utilisation\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recherche URL : https://www.goodreads.com/search?q=The+Guardians+John+Grisham\n",
      "URL trouvé : https://www.goodreads.com/book/show/43701061-the-guardians?from_search=true&from_srp=true&qid=WkIxLN6JDG&rank=1\n",
      "Note moyenne : 4.14\n"
     ]
    }
   ],
   "source": [
    "# Le script utilise Selenium pour récupérer l'URL d'un livre sur Goodreads à partir de son titre et de son auteur, puis nous permet d'extraire la note moyenne du livre.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Configurer les options Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")  # Vous pouvez réactiver le mode headless si nécessaire\n",
    "\n",
    "# Définir le chemin du ChromeDriver\n",
    "service = Service(executable_path=r'C:\\Users\\User\\Downloads\\CoursAlternance\\Chefoeuvre\\RecommendationsLectures\\chromedriver-win64\\chromedriver.exe')\n",
    "\n",
    "# Initialiser ChromeDriver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Fonction pour récupérer l'URL du premier résultat Goodreads\n",
    "def get_goodreads_url(title, author):\n",
    "    search_url = f\"https://www.goodreads.com/search?q={title.replace(' ', '+')}+{author.replace(' ', '+')}\"\n",
    "    print(f\"Recherche URL : {search_url}\")\n",
    "    \n",
    "    driver.get(search_url)\n",
    "    \n",
    "    try:\n",
    "        # Attendre que le premier résultat de la recherche apparaisse\n",
    "        first_result = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'a.bookTitle'))\n",
    "        )\n",
    "        \n",
    "        # Récupérer l'URL du premier résultat\n",
    "        book_url = first_result.get_attribute('href')\n",
    "        print(f\"URL trouvé : {book_url}\")\n",
    "        return book_url\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la recherche de l'URL pour {title} par {author}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fonction pour récupérer la note moyenne du livre\n",
    "def get_book_rating(book_url):\n",
    "    driver.get(book_url)\n",
    "    \n",
    "    # Attendre que la page soit chargée\n",
    "    time.sleep(5)\n",
    "    \n",
    "    try:\n",
    "        # Essayer d'extraire la note moyenne\n",
    "        rating = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div.RatingStatistics__rating'))\n",
    "        ).text\n",
    "        print(f\"Note moyenne : {rating}\")\n",
    "        return rating\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction de la note : {e}\")\n",
    "        return None\n",
    "\n",
    "# Test avec un livre\n",
    "title = \"The Guardians\"\n",
    "author = \"John Grisham\"\n",
    "book_url = get_goodreads_url(title, author)\n",
    "\n",
    "# Si l'URL du livre a été récupérée, on récupère la note moyenne\n",
    "if book_url:\n",
    "    get_book_rating(book_url)\n",
    "\n",
    "# Fermer le navigateur\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le script créé permet maintenant de recuperer la note pour un livre donné ainsi que son url associé dans goodreads, il ne reste plus qu'a lappliquer aux livres d'un csv donné , essayons avec books_2019\n",
    "\n",
    "# Faire attention à la versçion de chrome , qui avec les MAJ ne marchent plus avec le chromedriver téléchargé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du livre : The Evening and the Morning de Ken Follett\n",
      "Traitement du livre : Troubled Blood de Robert Galbraith\n",
      "Traitement du livre : To Sleep in a Sea of Stars de Christopher Paolini\n",
      "Traitement du livre : Shadows in Death de J. D. Robb\n",
      "Traitement du livre : The Vanishing Half de Brit Bennett\n",
      "Traitement du livre : All the Devils Are Here de Louise Penny\n",
      "Traitement du livre : Piranesi de Susanna Clarke\n",
      "Traitement du livre : New Ruth Ware Thriller de Ruth Ware\n",
      "Erreur lors de la recherche de l'URL pour New Ruth Ware Thriller par Ruth Ware: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF78F70E1F5+2972373]\n",
      "\t(No symbol) [0x00007FF78F3A55F0]\n",
      "\t(No symbol) [0x00007FF78F2457FA]\n",
      "\t(No symbol) [0x00007FF78F295A3E]\n",
      "\t(No symbol) [0x00007FF78F295D2C]\n",
      "\t(No symbol) [0x00007FF78F2DEAB7]\n",
      "\t(No symbol) [0x00007FF78F2BBABF]\n",
      "\t(No symbol) [0x00007FF78F2DB8CC]\n",
      "\t(No symbol) [0x00007FF78F2BB823]\n",
      "\t(No symbol) [0x00007FF78F2875E8]\n",
      "\t(No symbol) [0x00007FF78F288751]\n",
      "\tGetHandleVerifier [0x00007FF78F7347BD+3129501]\n",
      "\tGetHandleVerifier [0x00007FF78F784D00+3458528]\n",
      "\tGetHandleVerifier [0x00007FF78F77B05D+3418429]\n",
      "\tGetHandleVerifier [0x00007FF78F50687B+844123]\n",
      "\t(No symbol) [0x00007FF78F3B0AFF]\n",
      "\t(No symbol) [0x00007FF78F3AC6D4]\n",
      "\t(No symbol) [0x00007FF78F3AC86D]\n",
      "\t(No symbol) [0x00007FF78F39BD79]\n",
      "\tBaseThreadInitThunk [0x00007FF9F91F7374+20]\n",
      "\tRtlUserThreadStart [0x00007FF9FA3DCC91+33]\n",
      "\n",
      "Traitement du livre : The Guest List de Lucy Foley\n",
      "Traitement du livre : Squeeze Me de Carl Hiaasen\n",
      "Traitement du livre : Fifty Words for Rain de Asha Lemmie\n",
      "Traitement du livre : Blackout de Candace Owens\n",
      "Traitement du livre : Disloyal: A Memoir de Michael Cohen\n",
      "Traitement du livre : Killing Crazy Horse de Bill O'Reilly, Martin Dugard\n",
      "Traitement du livre : Caste de Isabel Wilkerson\n",
      "Traitement du livre : Compromised de Peter Strzok\n",
      "Traitement du livre : Untamed de Glennon Doyle\n",
      "Traitement du livre : Speaking for Myself de Sarah Huckabee Sanders\n",
      "Traitement du livre : Everything Beautiful in Its Time de Jenna Bush Hager\n",
      "Traitement du livre : Live Free Or Die de Sean Hannity\n",
      "Traitement du livre : Melania and Me de Stephanie Winston Wolkoff\n",
      "Traitement du livre : The Evening and the Morning de Ken Follett\n",
      "Traitement du livre : Troubled Blood de Robert Galbraith\n",
      "Traitement du livre : To Sleep in a Sea of Stars de Christopher Paolini\n",
      "Traitement du livre : The Vanishing Half de Brit Bennett\n",
      "Traitement du livre : Shadows in Death de J. D. Robb\n",
      "Traitement du livre : Piranesi de Susanna Clarke\n",
      "Traitement du livre : New Ruth Ware Thriller de Ruth Ware\n",
      "Erreur lors de la recherche de l'URL pour New Ruth Ware Thriller par Ruth Ware: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF78F70E1F5+2972373]\n",
      "\t(No symbol) [0x00007FF78F3A55F0]\n",
      "\t(No symbol) [0x00007FF78F2457FA]\n",
      "\t(No symbol) [0x00007FF78F295A3E]\n",
      "\t(No symbol) [0x00007FF78F295D2C]\n",
      "\t(No symbol) [0x00007FF78F2DEAB7]\n",
      "\t(No symbol) [0x00007FF78F2BBABF]\n",
      "\t(No symbol) [0x00007FF78F2DB8CC]\n",
      "\t(No symbol) [0x00007FF78F2BB823]\n",
      "\t(No symbol) [0x00007FF78F2875E8]\n",
      "\t(No symbol) [0x00007FF78F288751]\n",
      "\tGetHandleVerifier [0x00007FF78F7347BD+3129501]\n",
      "\tGetHandleVerifier [0x00007FF78F784D00+3458528]\n",
      "\tGetHandleVerifier [0x00007FF78F77B05D+3418429]\n",
      "\tGetHandleVerifier [0x00007FF78F50687B+844123]\n",
      "\t(No symbol) [0x00007FF78F3B0AFF]\n",
      "\t(No symbol) [0x00007FF78F3AC6D4]\n",
      "\t(No symbol) [0x00007FF78F3AC86D]\n",
      "\t(No symbol) [0x00007FF78F39BD79]\n",
      "\tBaseThreadInitThunk [0x00007FF9F91F7374+20]\n",
      "\tRtlUserThreadStart [0x00007FF9FA3DCC91+33]\n",
      "\n",
      "Traitement du livre : All the Devils Are Here de Louise Penny\n",
      "Traitement du livre : Anxious People de Fredrik Backman\n",
      "Traitement du livre : Transcendent Kingdom de Yaa Gyasi\n",
      "Traitement du livre : Fifty Words for Rain de Asha Lemmie\n",
      "Traitement du livre : The Guest List de Lucy Foley\n",
      "Traitement du livre : Blackout de Candace Owens\n",
      "Traitement du livre : Disloyal: A Memoir de Michael Cohen\n",
      "Traitement du livre : Killing Crazy Horse de Bill O'Reilly, Martin Dugard\n",
      "Traitement du livre : Caste de Isabel Wilkerson\n",
      "Traitement du livre : Compromised de Peter Strzok\n",
      "Traitement du livre : Untamed de Glennon Doyle\n",
      "Traitement du livre : Live Free Or Die de Sean Hannity\n",
      "Traitement du livre : Speaking for Myself de Sarah Huckabee Sanders\n",
      "Traitement du livre : Everything Beautiful in Its Time de Jenna Bush Hager\n",
      "Traitement du livre : Melania and Me de Stephanie Winston Wolkoff\n",
      "Traitement du livre : His Truth Is Marching On de Jon Meacham\n",
      "Traitement du livre : Eat a Peach de David Chang, Gabe Ulla\n",
      "Traitement du livre : I'm Thinking of Ending Things de Iain Reid\n",
      "Traitement du livre : This Tender Land de William Kent Krueger\n",
      "Traitement du livre : The Midwife Murders de James Patterson\n",
      "Traitement du livre : The Home Edit Life de Clea Shearer, Joanna Teplin\n",
      "Traitement du livre : Think Like a Monk: The secret of how to harness the power of positivity and be happy now de Jay Shetty\n",
      "Traitement du livre : Doesn't Hurt to Ask de Trey Gowdy\n",
      "Traitement du livre : Welcome Home de Myquillyn Smith\n",
      "Traitement du livre : Rowley Jefferson's Awesome Friendly Adventure de Jeff Kinney\n",
      "Traitement du livre : The One and Only Bob de Katherine Applegate\n",
      "Traitement du livre : The Silver Arrow de Lev Grossman\n",
      "Traitement du livre : I Promise de LeBron James\n",
      "Traitement du livre : The Wonderful Things You Will Be de Emily Winfield Martin\n",
      "Traitement du livre : I Am Every Good Thing de Derrick Barnes\n",
      "Traitement du livre : The Bad Guys in The One?! (The Bad Guys #12) de Aaron Blabey\n",
      "Traitement du livre : Stamped: Racism, Antiracism, and You de Jason Reynolds, Ibram X. Kendi\n",
      "Traitement du livre : Grown de Tiffany D. Jackson\n",
      "Traitement du livre : The Lost Book of the White de Cassandra Clare, Wesley Chu\n",
      "Traitement du livre : Punching the Air de Ibi Zoboi, Yusef Salaam\n",
      "Traitement du livre : Clap When You Land de Elizabeth Acevedo\n",
      "Traitement du livre : Hawk: A Maximum Ride Novel de James Patterson\n",
      "Traitement du livre : The Guest List de Lucy Foley\n",
      "Traitement du livre : The Vanishing Half de Brit Bennett\n",
      "Traitement du livre : Critical Mass de Craig Alanson\n",
      "Traitement du livre : The Silent Wife de Karin Slaughter\n",
      "Traitement du livre : Pretty Things de Janelle Brown\n",
      "Traitement du livre : American Dirt de Jeanine Cummins\n",
      "Traitement du livre : The Dutch House de Ann Patchett\n",
      "Erreur lors de l'extraction de la note : Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF78F70E1F5+2972373]\n",
      "\t(No symbol) [0x00007FF78F3A55F0]\n",
      "\t(No symbol) [0x00007FF78F2457FA]\n",
      "\t(No symbol) [0x00007FF78F295A3E]\n",
      "\t(No symbol) [0x00007FF78F295D2C]\n",
      "\t(No symbol) [0x00007FF78F2DEAB7]\n",
      "\t(No symbol) [0x00007FF78F2BBABF]\n",
      "\t(No symbol) [0x00007FF78F2DB8CC]\n",
      "\t(No symbol) [0x00007FF78F2BB823]\n",
      "\t(No symbol) [0x00007FF78F2875E8]\n",
      "\t(No symbol) [0x00007FF78F288751]\n",
      "\tGetHandleVerifier [0x00007FF78F7347BD+3129501]\n",
      "\tGetHandleVerifier [0x00007FF78F784D00+3458528]\n",
      "\tGetHandleVerifier [0x00007FF78F77B05D+3418429]\n",
      "\tGetHandleVerifier [0x00007FF78F50687B+844123]\n",
      "\t(No symbol) [0x00007FF78F3B0AFF]\n",
      "\t(No symbol) [0x00007FF78F3AC6D4]\n",
      "\t(No symbol) [0x00007FF78F3AC86D]\n",
      "\t(No symbol) [0x00007FF78F39BD79]\n",
      "\tBaseThreadInitThunk [0x00007FF9F91F7374+20]\n",
      "\tRtlUserThreadStart [0x00007FF9FA3DCC91+33]\n",
      "\n",
      "Traitement du livre : The Summer House de James Patterson\n",
      "Traitement du livre : A Private Cathedral de James Lee Burke\n",
      "Traitement du livre : 28 Summers de Elin Hilderbrand\n",
      "Traitement du livre : Caste de Isabel Wilkerson\n",
      "Traitement du livre : Untamed de Glennon Doyle\n",
      "Traitement du livre : Live Free Or Die de Sean Hannity\n",
      "Traitement du livre : Breath de James Nestor\n",
      "Traitement du livre : Finding Freedom de Omid Scobie, Carolyn Durand\n",
      "Traitement du livre : It Was All a Lie de Stuart Stevens\n",
      "Traitement du livre : Hoax de Brian Stelter\n",
      "Traitement du livre : Evil Geniuses de Kurt Andersen\n",
      "Traitement du livre : Doesn't Hurt to Ask de Trey Gowdy\n",
      "Traitement du livre : The Lazy Genius Way de Kendra Adachi\n",
      "Traitement du livre : The Biggest Bluff de Maria Konnikova\n",
      "Traitement du livre : Becoming Brianna de Terri Libenson\n",
      "Traitement du livre : The Umbrella Academy Volume 2: Dallas (Deluxe Edition) de Gerard Way\n",
      "Erreur lors de la recherche de l'URL pour The Umbrella Academy Volume 2: Dallas (Deluxe Edition) par Gerard Way: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF78F70E1F5+2972373]\n",
      "\t(No symbol) [0x00007FF78F3A55F0]\n",
      "\t(No symbol) [0x00007FF78F2457FA]\n",
      "\t(No symbol) [0x00007FF78F295A3E]\n",
      "\t(No symbol) [0x00007FF78F295D2C]\n",
      "\t(No symbol) [0x00007FF78F2DEAB7]\n",
      "\t(No symbol) [0x00007FF78F2BBABF]\n",
      "\t(No symbol) [0x00007FF78F2DB8CC]\n",
      "\t(No symbol) [0x00007FF78F2BB823]\n",
      "\t(No symbol) [0x00007FF78F2875E8]\n",
      "\t(No symbol) [0x00007FF78F288751]\n",
      "\tGetHandleVerifier [0x00007FF78F7347BD+3129501]\n",
      "\tGetHandleVerifier [0x00007FF78F784D00+3458528]\n",
      "\tGetHandleVerifier [0x00007FF78F77B05D+3418429]\n",
      "\tGetHandleVerifier [0x00007FF78F50687B+844123]\n",
      "\t(No symbol) [0x00007FF78F3B0AFF]\n",
      "\t(No symbol) [0x00007FF78F3AC6D4]\n",
      "\t(No symbol) [0x00007FF78F3AC86D]\n",
      "\t(No symbol) [0x00007FF78F39BD79]\n",
      "\tBaseThreadInitThunk [0x00007FF9F91F7374+20]\n",
      "\tRtlUserThreadStart [0x00007FF9FA3DCC91+33]\n",
      "\n",
      "Traitement du livre : Stranger Planet de Nathan W. Pyle\n",
      "Traitement du livre : Critical Role: Vox Machina Origins Volume II de Critical Role, Matt Mercer, Jody Houser\n",
      "Traitement du livre : Venus in the Blind Spot de Junji Ito\n",
      "Traitement du livre : Golden In Death de J. D. Robb\n",
      "Traitement du livre : The Cornwalls Vanish (previously published as The Cornwalls Are Gone) de James Patterson\n",
      "Erreur lors de la recherche de l'URL pour The Cornwalls Vanish (previously published as The Cornwalls Are Gone) par James Patterson: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF78F70E1F5+2972373]\n",
      "\t(No symbol) [0x00007FF78F3A55F0]\n",
      "\t(No symbol) [0x00007FF78F2457FA]\n",
      "\t(No symbol) [0x00007FF78F295A3E]\n",
      "\t(No symbol) [0x00007FF78F295D2C]\n",
      "\t(No symbol) [0x00007FF78F2DEAB7]\n",
      "\t(No symbol) [0x00007FF78F2BBABF]\n",
      "\t(No symbol) [0x00007FF78F2DB8CC]\n",
      "\t(No symbol) [0x00007FF78F2BB823]\n",
      "\t(No symbol) [0x00007FF78F2875E8]\n",
      "\t(No symbol) [0x00007FF78F288751]\n",
      "\tGetHandleVerifier [0x00007FF78F7347BD+3129501]\n",
      "\tGetHandleVerifier [0x00007FF78F784D00+3458528]\n",
      "\tGetHandleVerifier [0x00007FF78F77B05D+3418429]\n",
      "\tGetHandleVerifier [0x00007FF78F50687B+844123]\n",
      "\t(No symbol) [0x00007FF78F3B0AFF]\n",
      "\t(No symbol) [0x00007FF78F3AC6D4]\n",
      "\t(No symbol) [0x00007FF78F3AC86D]\n",
      "\t(No symbol) [0x00007FF78F39BD79]\n",
      "\tBaseThreadInitThunk [0x00007FF9F91F7374+20]\n",
      "\tRtlUserThreadStart [0x00007FF9FA3DCC91+33]\n",
      "\n",
      "Traitement du livre : Labyrinth de Catherine Coulter\n",
      "Traitement du livre : Deadly Touch de Heather Graham\n",
      "Traitement du livre : The Outsider de Stephen King\n",
      "Traitement du livre : Pax et le petit soldat de Sara Pennypacker\n",
      "Traitement du livre : This Book Is Anti-Racist de Tiffany Jewell\n",
      "Processus terminé. Le fichier avec les notes est enregistré sous books_with_ratings_2020.csv\n"
     ]
    }
   ],
   "source": [
    "# On utilise Selenium pour récupérer des informations sur les livres à partir du site Goodreads, et les enregistre dans un fichier CSV. Plus précisément,\n",
    "#  il lit une liste de livres depuis un fichier CSV (avec les colonnes \"title\" et \"authors\"), récupère l'URL de chaque livre sur Goodreads, puis extrait la note moyenne du livre et la stocke dans un nouveau fichier CSV \n",
    "# au format : books_with_ratings_2024.csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Configurer les options Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")  # Activez si vous voulez exécuter sans interface graphique\n",
    "\n",
    "# Définir le chemin du ChromeDriver\n",
    "service = Service(executable_path=r'C:\\Users\\User\\Downloads\\CoursAlternance\\Chefoeuvre\\RecommendationsLectures\\chromedriver-win64\\chromedriver.exe')\n",
    "\n",
    "# Initialiser ChromeDriver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Fonction pour récupérer l'URL du premier résultat Goodreads\n",
    "def get_goodreads_url(title, author):\n",
    "    search_url = f\"https://www.goodreads.com/search?q={title.replace(' ', '+')}+{author.replace(' ', '+')}\"\n",
    "    \n",
    "    driver.get(search_url)\n",
    "    \n",
    "    try:\n",
    "        # Attendre que le premier résultat de la recherche apparaisse\n",
    "        first_result = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'a.bookTitle'))\n",
    "        )\n",
    "        \n",
    "        # Récupérer l'URL du premier résultat\n",
    "        book_url = first_result.get_attribute('href')\n",
    "        return book_url\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la recherche de l'URL pour {title} par {author}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fonction pour récupérer la note moyenne du livre\n",
    "def get_book_rating(book_url):\n",
    "    driver.get(book_url)\n",
    "    \n",
    "    # Attendre que la page soit chargée\n",
    "    time.sleep(5)\n",
    "    \n",
    "    try:\n",
    "        # Essayer d'extraire la note moyenne\n",
    "        rating = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div.RatingStatistics__rating'))\n",
    "        ).text\n",
    "        return rating\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction de la note : {e}\")\n",
    "        return \"Note non disponible\"\n",
    "\n",
    "# Charger le fichier CSV d'entrée\n",
    "input_csv = r'C:\\Users\\User\\Downloads\\CoursAlternance\\Chefoeuvre\\RecommendationsLectures\\books_2020_Second.csv'  # Remplacez par le chemin réel de votre fichier CSV\n",
    "output_csv = 'books_with_ratings_2020.csv'\n",
    "\n",
    "# Charger le CSV avec pandas\n",
    "books_df = pd.read_csv(input_csv)\n",
    "\n",
    "# Ajouter une colonne pour les notes dans le DataFrame\n",
    "books_df['Goodreads Rating'] = None\n",
    "\n",
    "# Traiter chaque livre dans le CSV\n",
    "for index, row in books_df.iterrows():\n",
    "    title = row['title']\n",
    "    author = row['authors']\n",
    "    \n",
    "    print(f\"Traitement du livre : {title} de {author}\")\n",
    "    \n",
    "    # Récupérer l'URL du livre sur Goodreads\n",
    "    book_url = get_goodreads_url(title, author)\n",
    "    \n",
    "    # Si une URL est trouvée, récupérer la note\n",
    "    if book_url:\n",
    "        rating = get_book_rating(book_url)\n",
    "    else:\n",
    "        rating = \"Note non disponible\"\n",
    "    \n",
    "    # Mettre à jour la colonne 'Goodreads Rating' avec la note\n",
    "    books_df.at[index, 'Goodreads Rating'] = rating\n",
    "\n",
    "# Sauvegarder le nouveau DataFrame dans un fichier CSV\n",
    "books_df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Fermer le navigateur\n",
    "driver.quit()\n",
    "\n",
    "print(f\"Processus terminé. Le fichier avec les notes est enregistré sous {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A priori cela n'ouvre qu'une seule page google pour toutes les recherches pas une par titre donc ca va , meme si c'est long cela ne devrait pas bloquer l'ordinateur , \n",
    "# Chercher une methode pour le mettre en arriere plan? \n",
    "\n",
    "# Est ce que c'est legal , je dois respecter les regles RGPD ??\n",
    "# ENLEVER LES DOUBLONS ETC , EDA !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On a donc validé 3 méthodes si je me trompe pas :\n",
    "# Un service web (API de NYTIMEs pour creer une liste de bestsellers pour une date donnée puis filtrage avec l'API de google books pour verifier qu'ils sont bien de l'année en question)\n",
    "# un fichier de données (fichier csv de kaggle comme base)\n",
    "# Scraping ( de Goodreads avec selenium car bloque beautifulsoup pour recuperer les notes pour les livres scrapés )\n",
    "\n",
    "# Manque :\n",
    "# Base de données ( doit recuperer un fichier sql ou ?)\n",
    "# Un systeme big data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire d'une base de données (créée au préalable ?postgresql?) certaines données pour valider une nouvelle competence \n",
    "#Idéalement avec les données d'une année pas gérée encore , 2020 ? meilleure version 'books_with_ratings_2020.csv' donc apres etre processé plusieurs fois pour filtrer les bons de la bonne année et recuperer la note lié"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va utilsier pgadmin , qui est un outil qui permet de gerer PostgreSQL (est un système de gestion de base de données relationnelle et objet)\n",
    "# Tres galere avec sql je vais envoyer le csv directement dans pgadmin\n",
    "# Pour configurer un serveur local, on peut le faire en cliquant sur Add New Server.\n",
    "# développer la section Databases et sélectionner la base de données ou en créer une nouvelle si nécessaire (clic droit sur Databases > Create > Database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreurs trouvées dans le fichier CSV :\n",
      "Erreur dans les entêtes : ['title', 'authors', 'description', 'published_date', 'categories', 'Goodreads Rating'] ne correspond pas à ['title', 'authors', 'description', 'published_date', 'categories', 'goodreads_rating']\n",
      "Ligne 5: Format de date incorrect '2020' (attendu: YYYY-MM-DD).\n",
      "Ligne 8: 'goodreads_rating' n'est pas un nombre valide : 'Note non disponible'\n",
      "Ligne 16: Format de date incorrect '2020-09' (attendu: YYYY-MM-DD).\n",
      "Ligne 25: Format de date incorrect '2020' (attendu: YYYY-MM-DD).\n",
      "Ligne 28: 'goodreads_rating' n'est pas un nombre valide : 'Note non disponible'\n",
      "Ligne 38: Format de date incorrect '2020-09' (attendu: YYYY-MM-DD).\n",
      "Ligne 67: Format de date incorrect '2020' (attendu: YYYY-MM-DD).\n",
      "Ligne 68: Format de date incorrect '2020' (attendu: YYYY-MM-DD).\n",
      "Ligne 72: 'goodreads_rating' n'est pas un nombre valide : 'Note non disponible'\n",
      "Ligne 75: Format de date incorrect '2020' (attendu: YYYY-MM-DD).\n",
      "Ligne 87: Format de date incorrect '2020' (attendu: YYYY-MM-DD).\n",
      "Ligne 88: 'goodreads_rating' n'est pas un nombre valide : 'Note non disponible'\n",
      "Ligne 93: 'goodreads_rating' n'est pas un nombre valide : 'Note non disponible'\n",
      "Ligne 97: Format de date incorrect '2020-01-03T00:00:00+01:00' (attendu: YYYY-MM-DD).\n"
     ]
    }
   ],
   "source": [
    "# Ce script en Python vérifie la validité d'un fichier CSV en analysant plusieurs aspects, tels que la correspondance des en-têtes, \n",
    "# le format des dates, la présence de valeurs vides, et la validité des notes numériques. \n",
    "# Il utilise des expressions régulières pour valider les formats et identifie des erreurs dans le fichier, puis affiche un rapport d'erreurs.\n",
    "\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def validate_csv(file_path):\n",
    "    # Compteurs et stockage d'erreurs\n",
    "    line_number = 0\n",
    "    errors = []\n",
    "    \n",
    "    # Expressions régulières pour les types de données\n",
    "    date_pattern = re.compile(r'^\\d{4}-\\d{2}-\\d{2}$')  # Format de date YYYY-MM-DD\n",
    "    numeric_pattern = re.compile(r'^\\d+(\\.\\d+)?$')  # Nombre avec ou sans décimales\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        headers = next(reader)  # Récupérer les entêtes\n",
    "        \n",
    "        # Vérifier les entêtes\n",
    "        expected_headers = ['title', 'authors', 'description', 'published_date', 'categories', 'goodreads_rating']\n",
    "        if headers != expected_headers:\n",
    "            errors.append(f\"Erreur dans les entêtes : {headers} ne correspond pas à {expected_headers}\")\n",
    "        \n",
    "        for row in reader:\n",
    "            line_number += 1\n",
    "            \n",
    "            # Vérifier le nombre de colonnes\n",
    "            if len(row) != len(expected_headers):\n",
    "                errors.append(f\"Ligne {line_number}: Nombre de colonnes incorrect ({len(row)} colonnes trouvées).\")\n",
    "                continue\n",
    "\n",
    "            # Vérifier si la colonne 'title' est vide\n",
    "            if not row[0].strip():\n",
    "                errors.append(f\"Ligne {line_number}: La colonne 'title' est vide.\")\n",
    "            \n",
    "            # Vérifier le format de la date dans la colonne 'published_date'\n",
    "            if not date_pattern.match(row[3].strip()):\n",
    "                errors.append(f\"Ligne {line_number}: Format de date incorrect '{row[3]}' (attendu: YYYY-MM-DD).\")\n",
    "            \n",
    "            # Vérifier si la colonne 'goodreads_rating' est numérique\n",
    "            if row[5].strip() and not numeric_pattern.match(row[5].strip()):\n",
    "                errors.append(f\"Ligne {line_number}: 'goodreads_rating' n'est pas un nombre valide : '{row[5]}'\")\n",
    "            \n",
    "            # Vérifier les retours à la ligne ou les caractères spéciaux\n",
    "            for i, column in enumerate(row):\n",
    "                if '\\n' in column:\n",
    "                    errors.append(f\"Ligne {line_number}, colonne {i+1}: Retour à la ligne inattendu.\")\n",
    "    \n",
    "    # Résultats\n",
    "    if errors:\n",
    "        print(\"Erreurs trouvées dans le fichier CSV :\")\n",
    "        for error in errors:\n",
    "            print(error)\n",
    "    else:\n",
    "        print(\"Le fichier CSV est valide. Aucun problème trouvé.\")\n",
    "\n",
    "# Spécifie ici le chemin de ton fichier CSV\n",
    "csv_file_path = 'C:/Users/User/Downloads/CoursAlternance/Chefoeuvre/RecommendationsLectures/books_with_ratings_2020.csv'\n",
    "\n",
    "# Lancer la validation du CSV\n",
    "validate_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On a un souci encore , toutes les notes ne sont pas dispos, ce n'est pas le probleme central donc on va mettre la moyenne pour ceux à 0 et non disponibles : \n",
    "# On ajoute au script que si une note est trop basse ( inferieure a 3 ) qu'elle soit redressée a 3 , car cette liste vient quand meme des bestsellers du nytime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les notes Goodreads ont été ajustées et enregistrées dans C:/Users/User/Downloads/CoursAlternance/Chefoeuvre/RecommendationsLectures/booksGoodReadsRatings_2020_modifiedFINAL.csv.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def adjust_goodreads_rating(file_path, output_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "        headers = rows[0]  # En-têtes\n",
    "        \n",
    "        # Ouvrir un nouveau fichier pour écrire les modifications\n",
    "        with open(output_path, 'w', newline='', encoding='utf-8') as output_file:\n",
    "            writer = csv.writer(output_file)\n",
    "            writer.writerow(headers)  # Écrire les en-têtes\n",
    "            \n",
    "            for row in rows[1:]:\n",
    "                goodreads_rating = row[5].strip()  # Colonne goodreads_rating (6e colonne, index 5)\n",
    "                \n",
    "                # Vérifier si la note est 0 ou \"non disponible\"\n",
    "                if goodreads_rating == '0.00' or goodreads_rating.strip().lower() == 'note non disponible':\n",
    "                    # Générer un nombre aléatoire entre 3.7 et 3.9\n",
    "                    random_rating = round(random.uniform(3.7, 3.9), 2)\n",
    "                    row[5] = str(random_rating)  # Remplacer par la note générée\n",
    "                \n",
    "                else:\n",
    "                    # Vérifier si la note est un nombre valide\n",
    "                    try:\n",
    "                        rating = float(goodreads_rating)\n",
    "                        # Si la note est inférieure à 3, la redresser à 3\n",
    "                        if rating < 3:\n",
    "                            row[5] = '3.00'\n",
    "                    except ValueError:\n",
    "                        pass  # Ignorer les erreurs si la note n'est pas un nombre valide\n",
    "                \n",
    "                # Écrire la ligne modifiée\n",
    "                writer.writerow(row)\n",
    "    \n",
    "    print(f\"Les notes Goodreads ont été ajustées et enregistrées dans {output_path}.\")\n",
    "\n",
    "# Spécifie ici le chemin de ton fichier CSV et le fichier de sortie\n",
    "csv_file_path = 'C:/Users/User/Downloads/CoursAlternance/Chefoeuvre/RecommendationsLectures/books_with_ratings_2020.csv'\n",
    "output_csv_path = 'C:/Users/User/Downloads/CoursAlternance/Chefoeuvre/RecommendationsLectures/booksGoodReadsRatings_2020_modifiedFINAL.csv'\n",
    "\n",
    "# Remplacer les valeurs dans goodreads_rating et enregistrer dans un nouveau fichier\n",
    "adjust_goodreads_rating(csv_file_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok j'ai perdu enormement de temps en passant par pgadmin alors qu'en ligne de commande cela marche bien mieux . \n",
    "\n",
    "#On a envoyé le csv qui finit par 'GoodReadsRating_2020_modified.csv' dans pgadmin donc , l'objectif est de recuperer ces données donc? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans la compétence C1 il n'est pas encore demandé de faire des requetes sql si je ne me trompe pas donc on va juste recuperer les données stockées dans pgadmin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données ont été exportées avec succès dans le fichier donnéespgadmin2020.csv\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "\n",
    "# Connexion à la base de données PostgreSQL\n",
    "connection = psycopg2.connect(\n",
    "    host=\"localhost\",        # Adresse de ton serveur PostgreSQL\n",
    "    database=\"postgres\",      # Nom de ta base de données\n",
    "    user=\"postgres\",          # Nom d'utilisateur PostgreSQL\n",
    "    password=\"Lrk389229!\"     # Mot de passe PostgreSQL\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# S'assurer d'utiliser le schéma 'public'\n",
    "cursor.execute('SET search_path TO public;')\n",
    "\n",
    "# Requête SQL avec guillemets doubles autour du nom de la table pour gérer les caractères spéciaux\n",
    "query = 'SELECT title, authors, description, published_date, categories, goodreads_rating FROM \"public\".\"table_données_2020\";'\n",
    "cursor.execute(query)\n",
    "\n",
    "# Récupération des résultats\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Chemin et nom du fichier CSV\n",
    "csv_file_path = 'donnéespgadmin2020.csv'\n",
    "\n",
    "# Enregistrement des données dans le fichier CSV\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Écriture de l'en-tête\n",
    "    writer.writerow(['Title', 'Authors', 'Description', 'Published Date', 'Categories', 'Goodreads Rating'])\n",
    "    \n",
    "    # Écriture des données\n",
    "    for row in rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Les données ont été exportées avec succès dans le fichier {csv_file_path}\")\n",
    "\n",
    "# Fermeture de la connexion\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous reste l systeme big data , et chat propose des technos comme Hadoop , Spark ou encore NoSQL (MongoDB!!!)\n",
    "# Le Big Data se réfère généralement aux technologies conçues pour traiter et stocker de très grands volumes de données non structurées ou semi-structurées, \n",
    "# souvent au-delà des capacités des bases de données relationnelles comme PostgreSQL(PGAdmin). Les outils Big Data permettent aussi un traitement distribué et évolutif.\n",
    "\n",
    "# On a créé un docker compose , il faut donc classique : docker-compose up -d\n",
    "# On a également refait la manip pour obtenir un csv clean pour l'année 2021 appelé 'booksGoodReadsRatings_2021_modifiedFINAL' (facon d'appeler pour fichier traité final comme les autres années)\n",
    "# Tout : http://localhost:8084/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion bdd mongodb\n",
    "# admin et admin pour ID et password donc \n",
    "import pymongo\n",
    "\n",
    "# Connexion à MongoDB\n",
    "client = pymongo.MongoClient(\"mongodb://admin:admin@localhost:27019/\")\n",
    "db = client[\"my_database_2021\"]  # Remplace par ton nom de base de données\n",
    "collection = db[\"Books_2021\"]  # Remplace par le nom de la collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 documents insérés dans la collection Books_2021.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Chemin vers le fichier CSV (ajout du 'r' pour chaîne brute)\n",
    "csv_file_path = r'C:\\Users\\User\\Downloads\\CoursAlternance\\Chefoeuvre\\RecommendationsLectures\\booksGoodReadsRatings_2021.csv'\n",
    "\n",
    "# Lire le fichier CSV et insérer les données dans la collection MongoDB\n",
    "with open(csv_file_path, mode='r', encoding='utf-8') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    data_list = list(csv_reader)  # Convertir le lecteur CSV en liste de dictionnaires\n",
    "    if data_list:\n",
    "        collection.insert_many(data_list)  # Insérer toutes les lignes dans la collection MongoDB\n",
    "        print(f\"{len(data_list)} documents insérés dans la collection Books_2021.\")\n",
    "    else:\n",
    "        print(\"Le fichier CSV est vide ou mal formaté.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On a pu envoyer nos données dans mongo maintenant l'idée est de prouver qu'on peut récupéer/creeer un fichier de données a partir d'une collection dans mongo j'imagine ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier CSV a été recréé avec succès sous : C:\\Users\\User\\Downloads\\CoursAlternance\\Chefoeuvre\\RecommendationsLectures\\booksGoodReadsRatings_recreated_2021.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pymongo\n",
    "\n",
    "# Connexion à MongoDB\n",
    "client = pymongo.MongoClient(\"mongodb://admin:admin@localhost:27019/\")  # Assure-toi que le port 27019 est correct\n",
    "db = client[\"my_database_2021\"]  # Nom de la base de données\n",
    "collection = db[\"Books_2021\"]  # Nom de la collection\n",
    "\n",
    "# Chemin pour le fichier CSV recréé\n",
    "recreated_csv_path = 'C:\\\\Users\\\\User\\\\Downloads\\\\CoursAlternance\\\\Chefoeuvre\\\\RecommendationsLectures\\\\booksGoodReadsRatings_recreated_2021.csv'\n",
    "\n",
    "# Récupérer toutes les données depuis la collection MongoDB\n",
    "documents = list(collection.find())  # Convertir le curseur en liste\n",
    "\n",
    "# Vérifier si la collection contient des documents\n",
    "if len(documents) > 0:\n",
    "    # Ouvrir le fichier CSV pour l'écriture\n",
    "    with open(recreated_csv_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        \n",
    "        # Extraire les en-têtes (les clés du premier document)\n",
    "        headers = list(documents[0].keys())\n",
    "        csv_writer.writerow(headers)  # Écrire les en-têtes\n",
    "        \n",
    "        # Écrire chaque document (chaque ligne) dans le fichier CSV\n",
    "        for doc in documents:\n",
    "            csv_writer.writerow([doc.get(header, \"\") for header in headers])\n",
    "\n",
    "    print(f\"Le fichier CSV a été recréé avec succès sous : {recreated_csv_path}\")\n",
    "else:\n",
    "    print(\"La collection est vide ou n'a pas pu être récupérée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'essentiel est fait , je pense qu'il faudra tout de meme repasser sur les données , par exemple les categories ont l'air de manquer pour une bonne portion des nouveaux csv créés donc potentiellement revenir la dessus , et \n",
    "# mettre au propre les csv avec dans l'idée dans avoir qu'un gros au final (peut etre a faire dans la competence 2 ?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
