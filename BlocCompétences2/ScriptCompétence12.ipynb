{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C12. Programmer les tests automatisés d’un modèle d’intelligence artificielle en définissant les règles devalidation des jeux de données, des étapes de\n",
    "# préparation des données, d'entraînement, d’évaluation et de validation du modèle pour permettre son intégration en continu \n",
    "# et garantir un niveau de qualité élevé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Cas de Test et Règles de Validation par Étape\n",
    "\n",
    "#     Préparation des Données\n",
    "#         Partie visée : Traitement et validation des données d’entrée avant calcul des embeddings.\n",
    "#         Règles de validation :\n",
    "#             Vérifier que les données textuelles sont au format attendu (ex : chaînes non nulles, sans caractères spéciaux inappropriés).\n",
    "#             S'assurer qu'il n'y a pas de valeurs manquantes ou nulles dans les données textuelles à encoder.\n",
    "#         Stratégie : Exécuter des tests sur un échantillon de données pour confirmer que les textes sont dans un format compatible avec le modèle d'embeddings (SentenceTransformer).\n",
    "\n",
    "#     Calcul des Embeddings\n",
    "#         Partie visée : Fonction de calcul des embeddings.\n",
    "#         Règles de validation :\n",
    "#             Les embeddings produits doivent avoir une dimension constante (ici, 384 pour all-MiniLM-L6-v2).\n",
    "#             Aucun embedding ne doit contenir de valeurs infinies ou NaN.\n",
    "#         Stratégie : Vérifier la taille des embeddings générés sur un échantillon de données et confirmer qu'ils ne contiennent pas de valeurs problématiques.\n",
    "\n",
    "#     Calcul de la Similarité Cosinus\n",
    "#         Partie visée : Fonction calculate_cosine_similarity_in_batches.\n",
    "#         Règles de validation :\n",
    "#             La matrice de similarité doit être symétrique (ce qui est attendu pour une similarité cosinus).\n",
    "#             La taille de la matrice de similarité doit être correcte (dimensions N x N pour N embeddings).\n",
    "#         Stratégie : Utiliser des embeddings factices et vérifier la symétrie ainsi que les dimensions de la matrice.\n",
    "\n",
    "#     Recommandation de Livres (Évaluation du Modèle)\n",
    "#         Partie visée : Fonction recommander_livres_sans_categorie.\n",
    "#         Règles de validation :\n",
    "#             La fonction doit exclure le livre de référence des résultats de recommandation.\n",
    "#             Les livres recommandés doivent être triés par ordre décroissant de similarité.\n",
    "#             Au moins 3 recommandations doivent être fournies (si disponible).\n",
    "#         Stratégie : Utiliser un ensemble de données de test contenant plusieurs titres et vérifier que les recommandations respectent ces critères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Les outils de test (framework, bibliothèque, etc.) choisis sont cohérents avec l’environnement technique du projet.\n",
    "\n",
    "# Pour valider ce point, nous avons sélectionné des outils de test compatibles avec l'environnement de notebook basé sur Python, PyTorch, et SentenceTransformers.\n",
    "# Ces outils sont adaptés aux tests modulaires et à la validation de chaque étape dans des cellules individuelles.\n",
    "\n",
    "\n",
    "# Outils de Test Choisis et Cohérence avec l’Environnement\n",
    "# 1. Framework de Test : Utilisation des Assertions en Notebook\n",
    "\n",
    "#     Raisons :\n",
    "#         Nous utilisons des assertions directement dans les cellules de notebook pour vérifier les conditions de test, ce qui est adapté \n",
    "#         pour un environnement interactif.\n",
    "#         Cela permet d'exécuter chaque test indépendamment et d'obtenir des résultats immédiats sans avoir besoin d’un framework externe.\n",
    "#     Installation : Aucune installation requise pour l’utilisation des assertions.\n",
    "\n",
    "# 2. Manipulation et Validation de Données : pandas\n",
    "\n",
    "#     Raisons :\n",
    "#         pandas est utilisé pour gérer les données de livres (titres, auteurs, etc.) ; \n",
    "#         il permet de manipuler et de vérifier facilement les jeux de données pendant les tests en notebook.\n",
    "\n",
    "# 3. Modélisation et Calculs avec PyTorch : torch\n",
    "\n",
    "#     Raisons :\n",
    "#         torch est utilisé pour les embeddings et le calcul de similarité cosinus ; \n",
    "#         il est donc cohérent de l’utiliser également dans les tests pour vérifier la structure et le contenu des matrices de similarité.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3#  Les tests sont intégrés et respectent la couverture souhaitée établie.\n",
    "\n",
    "# Pour valider ce troisième point, nous allons écrire des cellules de tests en notebook qui couvrent chaque étape du processus \n",
    "# (préparation des données, calcul des embeddings, similarité cosinus, et recommandations).\n",
    "# Ces tests assureront une couverture complète des fonctionnalités critiques pour le modèle de recommandation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Test de Préparation des Données pour Toutes les Colonnes Clés\n",
    "\n",
    "# Ce test couvre chaque colonne du fichier CSV et vérifie :\n",
    "\n",
    "\n",
    "\n",
    "    # title et authors :\n",
    "    #     Vérifie l'absence de valeurs nulles et vides.\n",
    "\n",
    "    # description :\n",
    "    #     Assure qu'il n'y a pas de valeurs nulles ou vides et que les descriptions sont suffisamment longues.\n",
    "\n",
    "    # published_year :\n",
    "    #     Vérifie que la colonne ne contient pas de valeurs nulles et que chaque valeur est un entier (représentant une année valide).\n",
    "\n",
    "    # average_rating :\n",
    "    #     Vérifie l'absence de valeurs nulles et s'assure que chaque valeur est un nombre dans la plage de 0 à 5.\n",
    "\n",
    "    # categories :\n",
    "    #     Vérifie l'absence de valeurs nulles et confirme que chaque entrée contient du texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toutes les descriptions font au moins 1 caractère(s).\n",
      "Test de préparation des données pour toutes les colonnes clés : OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chargement du fichier CSV pour vérification\n",
    "csv_path = r\"C:\\Users\\User\\Downloads\\CoursAlternance\\Chefoeuvre\\RecommendationsLectures\\final_dataset_clean.csv\"\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Vérification des colonnes essentielles\n",
    "# 1. Vérification de la colonne 'title'\n",
    "assert data['title'].notnull().all(), \"Certaines entrées de titres sont nulles dans le CSV.\"\n",
    "assert data['title'].str.strip().astype(bool).all(), \"Certaines entrées de titres sont vides.\"\n",
    "\n",
    "# 2. Vérification de la colonne 'authors'\n",
    "assert data['authors'].notnull().all(), \"Certaines entrées d'auteurs sont nulles dans le CSV.\"\n",
    "assert data['authors'].str.strip().astype(bool).all(), \"Certaines entrées d'auteurs sont vides.\"\n",
    "\n",
    "# 3. Vérification de la colonne 'description' avec liste des titres si description < 1 caractère\n",
    "MIN_DESC_LENGTH = 1\n",
    "short_descriptions = data[data['description'].str.len() < MIN_DESC_LENGTH]\n",
    "\n",
    "# Si des descriptions sont trop courtes, lister les titres concernés\n",
    "if not short_descriptions.empty:\n",
    "    short_titles = short_descriptions['title'].tolist()\n",
    "    print(f\"Livres avec des descriptions trop courtes (< {MIN_DESC_LENGTH} caractères) :\")\n",
    "    for title in short_titles:\n",
    "        print(f\"- {title}\")\n",
    "else:\n",
    "    print(f\"Toutes les descriptions font au moins {MIN_DESC_LENGTH} caractère(s).\")\n",
    "\n",
    "# 4. Vérification de la colonne 'published_year' pour accepter entiers et floats\n",
    "assert data['published_year'].notnull().all(), \"Certaines années de publication sont nulles dans le CSV.\"\n",
    "assert data['published_year'].apply(lambda x: isinstance(x, (int, float))).all(), \"Certaines années de publication ne sont ni des entiers ni des floats.\"\n",
    "\n",
    "# 5. Vérification de la colonne 'average_rating'\n",
    "assert data['average_rating'].notnull().all(), \"Certaines notes moyennes sont nulles dans le CSV.\"\n",
    "assert data['average_rating'].apply(lambda x: isinstance(x, (int, float)) and 0 <= x <= 5).all(), \"Certaines notes moyennes ne sont pas dans la plage attendue (0-5).\"\n",
    "\n",
    "# 6. Vérification de la colonne 'categories'\n",
    "assert data['categories'].notnull().all(), \"Certaines catégories sont nulles dans le CSV.\"\n",
    "assert data['categories'].str.strip().astype(bool).all(), \"Certaines entrées de catégories sont vides.\"\n",
    "\n",
    "print(\"Test de préparation des données pour toutes les colonnes clés : OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Test de Calcul des Embeddings\n",
    "\n",
    "# Ce test vérifie que la colonne description est correctement transformée en embeddings, \n",
    "# avec la bonne dimension (384 pour le modèle all-MiniLM-L6-v2) et sans valeurs infinies ou NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de calcul des embeddings : OK\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Charger le modèle SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Générer des embeddings pour les 30 premières descriptions\n",
    "example_descriptions = data['description'].iloc[:30].tolist()\n",
    "embeddings = model.encode(example_descriptions, convert_to_tensor=True)\n",
    "\n",
    "# Test : Vérifier la dimension des embeddings\n",
    "assert embeddings.shape == (30, 384), \"La dimension des embeddings n'est pas correcte.\"\n",
    "\n",
    "# Test : Vérifier l'absence de NaN ou de valeurs infinies\n",
    "assert torch.isfinite(embeddings).all(), \"Les embeddings contiennent des valeurs infinies ou NaN.\"\n",
    "print(\"Test de calcul des embeddings : OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Test du Calcul de Similarité Cosinus en Lots\n",
    "\n",
    "# Ce test vérifie la symétrie de la matrice de similarité cosinus et ses dimensions. \n",
    "# La fonction utilise le produit matriciel pour calculer les similarités en lots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test du calcul de similarité cosinus : OK\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour calculer la similarité cosinus par lots\n",
    "def calculate_cosine_similarity_in_batches(embeddings, batch_size=10):\n",
    "    cosine_sim_list = []\n",
    "    for i in range(0, embeddings.shape[0], batch_size):\n",
    "        batch_embeddings = embeddings[i:i + batch_size]\n",
    "        batch_cosine_sim = torch.mm(batch_embeddings, embeddings.T)  # Produit matriciel\n",
    "        cosine_sim_list.append(batch_cosine_sim)\n",
    "    return torch.cat(cosine_sim_list)\n",
    "\n",
    "# Calculer la similarité cosinus pour les 30 descriptions\n",
    "cosine_sim = calculate_cosine_similarity_in_batches(embeddings)\n",
    "\n",
    "# Test : Vérifier les dimensions de la matrice de similarité\n",
    "assert cosine_sim.shape == (30, 30), \"La matrice de similarité cosinus a des dimensions incorrectes.\"\n",
    "\n",
    "# Test : Vérifier la symétrie de la matrice de similarité\n",
    "assert torch.allclose(cosine_sim, cosine_sim.T, atol=1e-6), \"La matrice de similarité cosinus n'est pas symétrique.\"\n",
    "print(\"Test du calcul de similarité cosinus : OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 30 premiers titres du dataset :\n",
      "1. Gilead\n",
      "2. Spider's Web\n",
      "3. The One Tree\n",
      "4. Rage of angels\n",
      "5. The Four Loves\n",
      "6. The Problem of Pain\n",
      "7. An Autobiography\n",
      "8. Empires of the Monsoon\n",
      "9. The Gap Into Madness\n",
      "10. Master of the Game\n",
      "11. If Tomorrow Comes\n",
      "12. Assassin's Apprentice\n",
      "13. Warhost of Vastmark\n",
      "14. The Once and Future King\n",
      "15. Murder in LaMut\n",
      "16. Jimmy the Hand\n",
      "17. Witness for the Prosecution & Selected Plays\n",
      "18. The Little House\n",
      "19. Mystical Paths\n",
      "20. Glittering Images\n",
      "21. Glamorous Powers\n",
      "22. The Mad Ship\n",
      "23. Post Captain\n",
      "24. The Reverse of the Medal\n",
      "25. Miss Marple\n",
      "26. The Years of Rice and Salt\n",
      "27. Spares\n",
      "28. Gravity\n",
      "29. The Wise Woman\n",
      "30. Girls' Night in\n"
     ]
    }
   ],
   "source": [
    "# Afficher les 30 premiers titres du DataFrame\n",
    "subset_data = data.iloc[:30]  # Sous-ensemble limité aux 30 premières lignes\n",
    "\n",
    "print(\"Les 30 premiers titres du dataset :\")\n",
    "for idx, title in enumerate(subset_data['title'], start=1):\n",
    "    print(f\"{idx}. {title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Test de la Fonction de Recommandation\n",
    "\n",
    "# Ce test vérifie que la fonction de recommandation retourne les livres les plus similaires \n",
    "# sans inclure le livre recherché lui-même dans les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de la fonction de recommandation : OK\n",
      "Recommandations : [('Post Captain', \"Patrick O'Brian\", 0.3553885817527771), ('The Little House', 'Philippa Gregory', 0.3518153429031372), ('The One Tree', 'Stephen R. Donaldson', 0.3289688527584076)]\n"
     ]
    }
   ],
   "source": [
    "# Limiter le DataFrame aux 30 premières lignes pour ce test\n",
    "subset_data = data.iloc[:30]\n",
    "\n",
    "# Fonction de recommandation modifiée pour travailler avec le sous-ensemble\n",
    "def recommander_livres_sans_categorie(titre_livre, data=subset_data, cosine_sim=cosine_sim, nb_recos=3):\n",
    "    # Chercher le livre par son titre (insensible à la casse)\n",
    "    results = data[data['title'].str.contains(titre_livre, case=False, na=False)]\n",
    "    \n",
    "    # Vérification de l'existence du livre\n",
    "    if results.empty:\n",
    "        print(f\"Le livre '{titre_livre}' n'existe pas dans la base.\")\n",
    "        return []\n",
    "    \n",
    "    # Récupération de l'index du premier résultat correspondant\n",
    "    idx = results.index[0]\n",
    "\n",
    "    # Calcul des scores de similarité pour le livre recherché\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Trier les livres par similarité (du plus similaire au moins similaire)\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Créer la liste des recommandations en excluant le livre lui-même (le premier de la liste)\n",
    "    recommendations = []\n",
    "    for i, score in sim_scores[1:nb_recos+1]:  # Ignorer le premier (le même livre)\n",
    "        livre_info = data.iloc[i]\n",
    "        recommendations.append((livre_info['title'], livre_info['authors'], score.item()))\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Exécuter le test de recommandation sur le sous-ensemble de données\n",
    "titre_recherche = \"Gilead\"\n",
    "recommendations = recommander_livres_sans_categorie(titre_recherche)\n",
    "\n",
    "# Test : Vérifier que le livre recherché est exclu des résultats\n",
    "assert all(rec[0] != titre_recherche for rec in recommendations), \"Le livre recherché est inclus dans les recommandations.\"\n",
    "\n",
    "# Test : Vérifier le nombre de recommandations (3 ou moins si moins de livres similaires sont disponibles)\n",
    "assert len(recommendations) == min(3, len(subset_data) - 1), f\"Le nombre de recommandations est incorrect : {len(recommendations)}\"\n",
    "\n",
    "print(\"Test de la fonction de recommandation : OK\")\n",
    "print(\"Recommandations :\", recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation pour l’Installation et l’Exécution des Tests\n",
    "# 1. Installation de l’Environnement de Test\n",
    "\n",
    "#     Environnement requis :\n",
    "#         Python 3.8 ou supérieur\n",
    "#         Accès à internet pour l’installation des packages\n",
    "\n",
    "# 2. Dépendances Requises\n",
    "\n",
    "# Voici les principales dépendances listées également dans le fichier requirements.txt :\n",
    "\n",
    "#     pandas : Manipulation des données pour les livres\n",
    "#     torch : Calcul des embeddings et similarités cosinus\n",
    "#     sentence-transformers : Modèle de transformation all-MiniLM-L6-v2\n",
    "#     pytest et pytest-cov : Outils pour les tests et la couverture de code\n",
    "\n",
    "# 3. Exécution des Tests\n",
    "\n",
    "#     Lancer les tests unitaires :\n",
    "#         Les tests sont configurés dans des cellules de notebook,un par un donc pour bien visualiser ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
